---
emoji: 🚀
title: (ADsP) 3과목(데이터 분석) 3장. 정형 데이터 마이닝 (下)
date: '2022-02-24 00:00:00'
author: choieastsea
tags: ADsp, 데이터분석준전문가, 빅데이터, 통계
categories: ADsP

---

본 글은 본인이 '데이터 분석 준전문가' 필기 시험을 준비하면서 개인적으로 작성하는 글이라 일부 이해가 되지 않고 부정확할 수 있음을 밝힙니다. 모두 화이팅^^

# 군집분석

> 비지도학습인 군집분석에 대해 학습한다.
>
> 군집분석을 통해 인사이트를 얻는 과정을 학습한다.

## 군집분석

군집분석이란 여러 변수로 표현된 자료들 사이의 유사성을 측정하고 유사한 자료들끼리 몇 개의 군집(cluster)으로 묶고 다변량 분석(상관분석, 회귀분석, 주성분 분석 등)을 활용하여 각 군집에 대한 특징을 파악하는 기법이다. 생물학에서의 종의 분류, 마케팅에서의 시장 세분화, 금융에서 산업 분석 등에 활용되며 `협엽 필터링(Collaborative Filtering)`같은 추천 서비스가 등장하는 기반을 제공하였다.

### 거리측도

1. 변수가 연속형인 경우

   - 유클라디안 거리(Euclidean)

     두 점 사이의 가장 짧은 거리를 계산. 통계적이지 않고 수학적인 거리로 변수들의 산포정도를 감안하지 않는다. == 좌표계에서 점과 점 사이의 거리

   - 맨하튼 거리(Manhattan)

     길을 따라 갔을 때의 거리. 시가 거리라고도 함. 가로지르지 않는 **축들의 차이의 합**이라고 볼 수 있다. x의 이동거리, y의 이동거리, z의 이동거리를 더한다.

   - 체비셰프 거리(Chebychev)

     **변수 간 거리 차이 중 최댓값**을 데이터 간의 거리로 정의한다. x,y,z 축이 있을 때 각 축에서 최대와 최소값의 차이를 구하고, 그 중 최대를 의미한다.

   - 표준화 거리(Standardized)

     유클리드 거리에서 변수 간 단위의 차이로 생기는 문제를 표준편차로 나눔으로써 해결한 거리이다.

   - 마할라노비스 거리

     표준화 거리에서 변수 간 상관성까지 고려한 거리이다.

   - 민코프스키 거리

     유클리디안 거리와 맨하튼 거리를 한번에 표현한 거리로, m=1일때는 맨하튼 거리이며, m=2 일때는 유클리디안 거리가 된다.

   유클라디안 거리, 맨하튼 거리, 체비셰프 거리를 비교해보자.

   A(1,2,3), B(2,6,-1)라고 했을 때, 각각의 거리를 구하면

   1. 유클라디안 : $\sqrt{(1-2)^2+(2-6)^2+(3+1)^2} = \sqrt{33}$
   2. 맨하튼 : $\abs{1-2}+\abs{2-6}+\abs{3+1} = 9$
   3. 체비셰프 : $max((1-2), (2-6), (3+1)) = 4$

2. 변수가 범주형인 경우 : 얼마나 공통된 요소를 갖고 있는지 판단 가능

   - 단순 일치 계수(Simple Matching Coefficient, SMC) : 두 객체의 상이성을 불일치 비율로 계산한다. p는 총 변수의 개수, m은 일치한 수를 의미한다. 즉 전체 중에 일치하지 않은 비율을 의미.

     $d(i,j) = \frac{p-m}{p}$

   - 자카드 지수 : 두 집합 사이의 유사도를 측정하는 지표로서 두 집합이 같으면 1, 완전 다르면 0이 된다. cap/cup으로 계산.

     $J(X,Y) = \frac{n(A\cap B)}{n(A\cup B)}$

   - 자카드 거리 : 자카드 지수를 거리화하기 위해, 1에서 자카드 지수를 뺀 값(같으면 0, 다르면 1이 되도록)

   - 코사인 유사도 : 텍스트의 유사도를 측정하기 위한 지표로서 크기가 아닌 방향성을 측정하는 지표다. 완전 일치하면 1, 완전 다른 방향이면 -1의 값을 갖는다.

     $Cosine Similarity(X,Y) = \frac{\overrightarrow{X}\cdot\overrightarrow{Y}}{\abs{X}\abs{Y}}$ : 두 내적값을 두 벡터의 크기의 곱으로 나눈 값이다. (내적은 단순하게 같은 좌표계끼리 곱해주면 됨)

   - 코사인 거리 : 코사인 유사도를 거리화하기 위해, 1에서 코사인 유사도를 뺀 값

   - 순위 상관 계수 : 순서척도인 두 데이터의 거리를 비교하기 위해 `스피어만 상관계수`를 이용

## 계층적 군집분석

개별 관측치 간의 거리를 계산하여 가장 가까운 관측지부터 결합해나가면서 계층적 트리 구조를 형성하고, 이를 통해 군집화를 수행하는 방법이다. 각 데이터를 하나의 군집으로 간주하고 가까운 데이터부터 순차적으로 병합하는 '병합적 방법'과 전체를 하나의 군집으로 간주하는 '분할적 방법'이 존재한다. '가깝다'라는 것은 어떻게 거리를 계산하냐에 따라 방법이 달라지게 된다.

### 군집 간의 거리

계층적 군집은 한 번 병합된 객체는 다시 분리되지 않고 사용되는 연결법에 따라 생성되는 군집이 달라진다. 따라서 여러 연결법을 통해 군집을 생성한 후, 유의미한 군집을 형성하는 방법을 적용하도록 한다.

- 군집간의 연결법
  1. 단일연결법(최단연결법) : 군집안의 데이터들과 기존의 데이터들의 거리를 가장 가까운 것을 거리로 계산한다.
  2. 완전연결법(최장연결법) : 군집안의 데이터들과 기존의 데이터들의 거리를 가장 먼 것을 거리로 병합한다.
  3. 평균연결법 : 각 데이터끼리의 거리의 평균을 계산하는 방법이다. 계산량은 불필요하게 많아지나 이상치에 덜 민감하다.
  4. 중심연결법 : 각 군집의 중심점 사이의 거리를 이용한다. 평균연결법보다 계산량이 적다.
  5. 와드연결법 : 생성된 군집과 기존의 데이터들의 거리를 군집 내 오차가 최소가 되는 데이터로 계산한다. 군집 내 분산을 최소로 하므로, 좀 더 조밀한 군집이 생성될 수 있다.

### 계층적 군집분석 실습



## 혼합 분포군집

## 자기조직화지도(SOM)



# 연관분석

> 마케팅에서 자주 사용되는 연관분석에 대해 학습한다.
>
> 연관분석의 다양한 알고리즘과 특징을 이해한다.
---
emoji: 🚀
title: (ADsP) 3과목(데이터 분석) 2장. 통계 분석 (上)
date: '2022-02-09 00:00:00'
author: choieastsea
tags: ADsp, 데이터분석준전문가, 빅데이터, 통계
categories: ADsP




---

본 글은 본인이 '데이터 분석 준전문가' 필기 시험을 준비하면서 개인적으로 작성하는 글이라 일부 이해가 되지 않고 부정확할 수 있음을 밝힙니다. 모두 화이팅^^

# 통계의 이해

> 통계의 기초 개념에 대해 학습한다.
>
> 추정과 가설검정은 통계에서 매우 중요한 개념이므로 반드시 숙지한다.



## 통계 개요

### 표본 조사

예컨데, 우리나라 국민들에 대한 통계분석을 한다고 가정해보자. `모집단` '우리나라 국민'은 너무 규모가 커서 전수조사는 불가능하다고 볼 수 있다. 그렇기에 모집단을 대표할 수 있는 `표본 집단`을 선별하여 `표본조사`를 실시한다. 표본집단은 모집단을 대표할 수 있는 집단이여야 하며 이를 `표본의 대표성`이라고 한다. 표본의 대표성을 신뢰할 수 있어야 표본조사를 통한 모집단의 통계분석 결과 또한 신뢰할 수  있다.

- 신뢰수준 & 오차범위

  신뢰수준 95%에 오차범위 ±3%라는 말은, 100번 조사했을 때, 오차 범위내에서 동일한 결과가 나올 확률이 95%라는 것이다.

- %와 %포인트

  %의 차이를 비교할 때, %포인트를 사용한다. ex) 작년 2%에서 올해 4%로 2%포인트 상승하였다.(%로 표현한다면 100%상승하였다)

### 표본 추출 방법

1. 단순 랜덤 추출법

   N개의 모집단에서 n개의 데이터를 무작위로 추출하는 방법

2. 계통 추출법

   각 원소에 번호를 부여한 뒤, 일정한 간격을 두고 추출하는 방법. N개의 모집단에서 K개씩 n개의 구간으로 나누어 각 구간별로 일정한 간격(K)으로 추출한다. 그럼 n개씩 추출 될 것이다.

3. 집락(군집 : cluster) 추출법

   데이터를 **여러 집락으로 구분**한 뒤, 단순 랜덤 추출법으로 선택된 집락을 표본으로 사용한다. 각 집락은 서로 비슷한 성질을 갖으며, 집락 내의 데이터는 서로 다양하게(모집단을 대표하도록) 분포한다. 예를 들어, 중학생을 조사할 때, 한 집락에는 1학년부터 3학년까지 다양하게 분포하지만, 각 집락끼리의 구성은 비슷할 것이다. 

4. 층화 추출법(stratified sampling)

   각 집락을 이질적으로, 군집 내 데이터는 동질적으로 구성한 후, 각 집락별로 데이터를 각각 추출한다. 위와 다르게, 이번에는 1학년 집락, 2학년, 3학년 집락으로 나눈 후, 각 집락에서 표본을 <u>몇개씩</u> 추출하는 것이다. 밑줄 친 몇개씩에 대하여 `비례 층화 추출법`과 `불비례 층화 추출법`으로 나뉜다. 

   - 비례 층화 추출법

     집락의 비율을 모집단의 비율을 유지하도록 추출한다. 예를 들어 1학년이 많으면 1학년 집락에서 더 많이 추출한다.

   - 불비례 층화 추출법

     전체 데이터의 분포를 반영하지 않고 원하는 군집에서 원하는 표본의 개수를 추출한다.

### 척도 

관측 대상의 속성을 측정하여 그 값이 **숫자로 나타나도록 하는** 도구

- 질적 척도
  - 명목 척도 : 측정 대상이 어느 집단에 속하는지 나타냄 (성별, 지역)
  - 순서(서열) 척도 : 측정 대상이 명목척도이면서 **서열 관계**를 갖음 (선호도, 신용도, 학년). *사칙연산 불가*
- 양적 척도
  - 구간(등간) 척도 : 측정 대상이 갖는 속성의 양을 측정할 수 있으며 두 구간 사이에 의미가 있는 자료 (온도, 지수)
  - 비율 척도 : 측정 대상이 구간척도이면서 **절대적 기준 0이 존재**하여 사칙연산이 가능한 자료 (신장, 무게, 점수, 가격)

척도의 종류를 구분할 수 있도록 하자!

### 기술 통계와 추리통계

간단하게 말하면, <u>기술통계는 표본집단을 분석하는데 쓰이고 추리통계는 표본으로 모집단을 분석하는데 쓰인다</u>.

- 기술 통계: 표본을 설명해주는 데이터의 최소,최대, 중위수 등
- 추리(추론) 통계: 표본에서 얻은 통계치를 바탕으로 오차를 고려하며 모수를 확률적으로 추정하는 통계

## 확률과 확률 분포

기본적인 확률에 대한 지식은 패스하도록 한다.

### 이산확률 분포 → 확률 질량 함수

- 이산확률 변수

  확률변수의 값의 수를 셀 수 있는 확률 변수. 서로 배반인 사건들의 합집합의 확률은 각 사건의 확률의 합과 같다.
  $$
  0 \leq p(X) \leq 1 \newline
  \sum p(x) = 1
  $$
  

  - 기댓값(=평균값)
    $$
    E(X) = \sum xf(x)
    $$
    
  - 분산 : 제평평제~
    $$
    Var(X) = E[(X-E(X))^2] =E(X^2)-E(X)^2 = \sum x^2f(x)-{E(X)}^2
    $$
    

1. 베르누이 분포

   확률 변수 X가 <u>취할 수 있는 값이 두 개인 경우</u>, 한 번의 시행을 할 때 성공과 실패로 나눌 수 있는 성공확률이 p인 분포

   동전을 한번 던져서 앞면이 나올 확률, 한번 보는 시험에 합격할 확률...
   $$
   P(X=x) = p^x(1-p)^1-x (단, x= 0,1)\newline
   E(X) = p\newline
   Var(X) = p(1-p)
   $$

2. 이항 분포

   n번의 베르누이 시행에서 k번 성공할 확률의 분포 (사건 발생/미발생의 여부로 판단 가능)

   동전을 세번 던져서 앞면이 2번 나올 확률, 주사위를 5번 던져서 1이 2번 나올 확률...
   $$
   P(X=k) = \binom nk p^x(1-p)^{n-x} (단, k=0,1,2,...,n)\newline
   E(X) = np\newline
   Var(X) = np(1-p)
   $$

3. 기하 분포

   성공확률이 p인 베르누이 시행에서 **처음으로 성공**이 나올 때까지 **k번 실패할 확률**

   동전을 던져서 3번째에야 첫 앞면이 나올 확률, 주사위를 던져서 4번째에야 2가 나올  확률...
   $$
   P(X=k) = p(1-p)^k (단, k=0,1,2,...,n)\newline
   E(X) = \frac{1}{p}\newline
   Var(X) = \frac{1-p}{p^2}
   $$

4. 다항 분포

   이항 분포의 확장으로, n번의 시행에서 각 시행이 3개 이상의 결과를 가질 때 확률 분포

   주사위를 n번 던졌을 때, 1이 a번, 2이상 5미만이 b번 나올 확률...
   $$
   P(X=x, Y=y, Z=z,...) = \frac{n!}{x!y!z!...}p_1^xp_2^yp_3^z...(단, x+y+z+...=n)\newline
   $$
   
5. 포아송 분포

   단위 시간 또는 단위 공간 내에서 발생할 수 있는 사건의 발생횟수에 대한 확률 분포

   8시간 동안 3번의 오류가 발생하였을 때, 1시간동안 2번의 오류가 발생할 확률
   $$
   P(X=x) = \frac{e^{-\lambda}\cdot\lambda^x}{x!} (단, \lambda는 단위 시간 또는 단위 공간당 사건 발생 비율)\newline
   E(X) = \lambda\newline
   Var(X) = \lambda
   $$
   

### 연속확률 분포 → 확률 밀도 함수

- 연속확률 변수
  
  확률변수가 취할 수 있는 값이 특정 구간 전체에 해당하여 셀 수 없는 변수, 확률 밀도 함수의 아래 면적이 확률을 의미함.
  
  - 평균 : $\int_{-\infty}^\infty xf(x)dx$
  
  - 분산 : $ Var(X) = \int(x-E(X))^2f(x)dx=\int_{-\infty}^\infty x^2f(x)dx-\int_{-\infty}^\infty xf(x)dx^2$

1. 균일 분포

   연속확률변수 X가 취할 수 있는 모든 값에 대하여 같은 확률을 갖음.(상수함수의 꼴을 띰)
   $$
   a부터 b까지 \frac{1}{b-a}로 확률이 일정하다고 할 때,\newline
   E(X) = \frac{a+b}{2}\newline
   Var(X) = \frac{(b-a)^2}{12}
   $$
   
2. 정규 분포

   평균이 $\mu$이고, 표준편차가 $\sigma$인 분포를 의미한다. 평균값에 가장 많이 몰려있는 종 모양의 그래프를 갖는다. 정규분포는 표준화를 통하여 평균이 0이고, 표준편차가 1인 표준정규분포로 변환할 수 있으며 이를 통하여 구간의 확률을 구할 수 있다.

3. t-분포

   평균이 0이고 좌우 대칭의 종모양이지만, 정규분포보다 두꺼운 꼬리를 갖는다. 자유도가 커질수록 표준정규분포에 가까워 진다.

   모평균 검정 또는 두 집단의 평균이 동일한지 계산하기 위한 검정통계량으로 활용된다.

4. 카이제곱분포

   표준정규분포를 따르는 확률변수 $Z_1$,$Z_2$,$Z_3$,...,$Z_n$의 제곱의 합 X는 자유도가 n인 카이제곱 분포를 따른다. 카이제곱분포는 모평균과 모분산을 모르는 **두 개 이상의 집단 간 동질성 검정 또는 모분산 검정**을 위해 활용된다.

5. F분포

   **등분산 검정 및 분산분석**을 위해 활용됨. (등분산 검정: 두 집단의 분산이 같은지 다른지 판별)

### 추가 개념

1. 첨도와 왜도

   - 첨도(kurtosis) : 확률분포의 뾰족한 정도. (높을수록 뾰족)3을 기준으로 나타내지만, 정규분포의 첨도를 0으로 나타내기 위해 3을 빼고 사용하기도 함

   - 왜도(skewness) : 확률분포의 비대칭 정도. (0기준 양수는 왼쪽 치우침). 0을 기준으로 정규분포와 같다.

     왜도 < 0 : 평균 < 중앙값 < 최빈값

     왜도 > 0 : 최빈값 < 중앙값 < 평균

2. 공분산과 상관계수

   - 공분산(Covariance) : 두 확률변수 X,Y의 상관 정도를 나타내는 값. 양수면 X가 증가할 때, Y도 증가하고 음수면 X 증가시 Y는 감소한다. 부호만 유의미하며, 선형성의 정도는 알 수 없다.

     $Cov(X,Y) = E[(X-\mu_X)(Y-\mu_Y)]$

   - 상관계수(Correlation) : -1과 1사이의 값을 갖고, 1(-1)에 가까울수록 양(음)의 상관관계를 나타낸다. 공분산을 X,Y의 표준편차로 나눈 값

     $r_{xy} = \frac{Cov(x,y)}{\sigma_x\sigma_y}$

## 추정과 가설검정

### 추정

궁극적으로 통계로 알고 싶은 것은 모집단의 분포 및 특성인데, 이는 불가능하므로 대부분 표본조사를 통하여 모수를 추정한다.

- 점추정

  모집단의 모수 중 평균을 추정할 때, 모평균을 하나의 값으로 특정하여 예측하는 것이다. *표본평균*이 대표적

  unbiased(불편) 추정량은 편향되지 않아 모수를 측정하기에 이상적인 값을 의미한다. 

- 구간추정

  모수가 특정한 구간에 존재할 것이라 예상하는 것이다. 신뢰도(신뢰수준)이 필요하며 이는 모수가 특정 구간 안에 포함될 확률이다.

### 가설 검정(!)

- 귀무 가설(`null hypothesis`, $H_0$)

  모집단이 어떠한 특징을 가질 것으로 여겨지는 가설. '차이가 없다', '같다' 등을 이용하여 표현함.

- 대립 가설(`alternative hypothesis`, $H_1$)

  귀무가설에 반대되는 가설로 귀무가설이 틀렸다고 판단될 경우 채택되는 가설.

- 제1종 오류

  <u>귀무가설이 사실인데, 틀렸다고 결정하는 오류</u>

- 제2종 오류

  <u>귀무가설이 사실이 아닌데도 옳다고 결정하는 오류</u>

- 가설 채택 근거

  - 검정 통계량: 귀무가설의 옳고 그름을 판단할 수 있는 값
  - 기각역 : 귀무가설을 기각하게 될 검정통계량의 영역, 검정통계량이 기각역 내에 있으면 귀무가설을 기각함
  - 유의수준($\alpha$, significance level) : 1종오류를 범할 확률의  최대 허용 한계. 주로 0.01과 0.05를 사용함
  - 유의확률(p-value, significance probability) : **귀무가설을 지지하는 정도**를 나타낸 확률.(어렵게는 귀무가설을 기각할 때 그 결정이 잘못되었을 확률)

- p-value가 유의수준보다 작은 경우 : <u>귀무가설을 기각한다</u>. (귀무가설 지지도가 낮으므로)

- 수집한 데이터나 증거가 “기존의 생각” 또는 “처음부터 믿고 있던 가설” 에 반대되는 **충분한 근거** 가 있다면 기존의 가설을 포기한다. 근거의 양은 p-value로 판단하고, 충분한의 근거는 유의수준에 따라 결정한다.

- 제 1종오류와 2종오류를 모두 줄일 수 있다면 이상적이지만, 서로 반비례관계이므로 유의수준을 정하여 가설검정을 수행한다.

### 모수검정 vs 비모수검정

- `모수적 특성` = 표본이 정규성을 갖는다. (정규분포를 따른다) 모수적 특성을 이용하는 모수검정
-  정규분포를 따르지 않는다고 증명되거나(by 정규성 검정) 소규모 실험에서와 같이 정규분포임을 가정할 수 없는 경우에 비모수검정을 사용한다. 이는 모수에 대한 어떠한 가정도 하지 않는다.
- 비모수검정에는 자료를 소팅하여 순위를 매긴다음 순위의 합을 통해 차이를 비교하는 `순위합검정`이 있다. 숫자지만 계산이 불가능한 서열척도의 경우에도(연속형 자료가 아니지만) 순위의 합을 이용하여 비모수적 검정이 가능하다.

| 모수 검정                                             | 비모수 검정                                                  |
| ----------------------------------------------------- | ------------------------------------------------------------ |
| 등간척도, 비율척도 **→ 양적척도**                     | 명목척도, 서열척도 **→ 질적척도**                            |
| 평균                                                  | 중앙값                                                       |
| 피어슨 상관계수                                       | 스피어만 순위상관계수                                        |
| one/two sample t-test, paired two test, one way anova | 부호검정, Wilcoxon 부호순위 검정, Mann-Whitney 검정, Kruskal Wallis 검정 |

# 기초 통계

> 차이를 검정하는 분석과 관계를 검정하는 분석에 대해 학습한다.
>
> 실제 실습 결과를 해석하는 법을 반드시 숙지한다.

## t-검정

### one sample t-test(일 표본 t-검정)

가설 검정 중 모수 검정의 일종으로, **하나의 모집단의 평균값을 특정값**과 비교하는 경우 사용된다.

- 일 표본 단측 t-검정 : **greater/less**

  모수값이 '~보다 크다/작다'와 같이 하나의 방향성을 갖는 경우 수행되는 검정 방법

  ex) '우리반 애들의 평균키는 남자 평균키인 175보다 크다' 라는 것을 보이려고 한다. (175라는 값은 모집단의 평균을 의미한다고 가정) 실제 키는 runif 함수를 이용하여 랜덤으로 대입해주었다.

  ```R
  #우리반 애들은 165부터 185까지 랜덤으로 있다(?ㅋㅋ)
  > classmate_heights <- runif(15, min=165, max=185)
  #여기서 귀무가설은 우리반 애들의 평균키는 175보다 크다. alternative(대립가설)은 '175 이하'가 될 것이다. mu는 모집단의 평균 의미
  > t.test(classmate_heights, mu=175, alternative='less')	
  
  	One Sample t-test
  
  data:  classmate_heights
  # t : 검정 통계량, df : 자유도(n(표본)-1) , p-value : 귀무가설에 대한 지지도
  t = -0.48401, df = 14, p-value = 0.3179
  # p-value가 유의수준(0.05)보다 높으므로 귀무가설이 옳다고 할 수 있다.
  alternative hypothesis: true mean is less than 175
  95 percent confidence interval:
       -Inf 176.7323
  sample estimates:
  mean of x 
   174.3436
  ```

  `p-value`가 정해놓은 유의수준(0.05)보다 높으므로 귀무가설이 채택될 수 있다. 만약 낮다면 대립가설인 '우리반 애들의 키가 175보다 작다'가 채택될 것이다. 위의 결과는 랜덤추출이므로 실행할 때마다 다른 결과가 나올 것이다.

- 일 표본 양측 t-검정 : **two.sided**

  모수값이 '~이다/이 아니다'와 같이 방향성이 없는 경우 수행되는 검정 방법

  ex) '우리반 애들의 평균 몸무게는 70kg이다'라는 것을 보이려고 한다. (70은 모집단의 평균 몸무게를 의미한다고 가정)

  ```R
  > classmate_weights <- runif(15, min=40, max=90)
  #이 때의 대립가설은 평균 몸무게는 70kg가 아니다. (70키로보다 크거나, 작을 것이다->two.sided)
  > t.test(classmate_weights, mu=70, alternative='two.sided')
  
  	One Sample t-test
  
  data:  classmate_weights
  t = -2.4058, df = 14, p-value = 0.03053
  #p-value가 유의수준(0.05)보다 낮으므로 귀무가설은 기각된다.
  alternative hypothesis: true mean is not equal to 70
  95 percent confidence interval:
   52.37512 68.98899
  sample estimates:
  mean of x 
   60.68206 
  ```

  `p-value`가 정해놓은 유의수준(0.05)보다 낮으므로 귀무가설이 기각되며 대립가설인 '70kg가 아니다'가 채택될 것이다.

### independent sample t-test(이/독립 표본 t-검정)

일 표본 t-검정과 다르게, **독립된 두 집단에 대하여 모수의 값이 같은 값을 같는지** 검정하는 방법이다. 이 역시 단측과 양측 검정이 존재한다.

- 이 표본 단측 t-검정

  ex) '3학년 10반보다 7반의 평균키가 작다'라는 귀무가설을 수립했다고 가정해보자. 당연하게도 10반과 7반은 독립이다. 위와 비슷하게 해볼 수 있을 것이다. 단지, `t.test( )`함수에 인자를 하나 더 넣어주면 된다. **기준이 되는 집단을 먼저** 넣어주는 것이 중요하다.

  ```R
  > class10_heights <- runif(15, 165, 185)
  > class7_heights <- runif(12, 162, 182)
  #10반의 평균키는 7반보다 크거나 같다. <=> 대립가설: 10반의 평균키는 7반보다 작다.
  > t.test(class10_heights, class7_heights, alternative='less')
  
  	Welch Two Sample t-test
  
  data:  class10_heights and class7_heights
  t = 0.29756, df = 23.336, p-value = 0.6157
  #p-value가 유의수준(0.05)보다 높으므로 귀무가설은 채택된다.
  alternative hypothesis: true difference in means is less than 0
  95 percent confidence interval:
       -Inf 4.614222
  sample estimates:
  mean of x mean of y 
   174.5426  173.8597
  ```

  귀무가설이 채택되면 10반이 7반보다 평균키가 크다고 할 수 있다. 이 표본의 경우, 자유도는 단순하게 표본 갯수에서 1을 뺀 것이 아닌 것도 확인할 수 있다.

- 이 표본 양측 t-검정

  양측이므로 단측(less, greater)가 아닌 '같다, 다르다' 정도로 표현할 수 있을 것이며 alternative(대립가설) 역시 two.sided로 표현하면 될 것이다. 위와 다 똑같으니 굳이 실행해보지는 않겠다.

### paired t-test(대응 표본 t-검정)

**동일한 대상**에 대해 두가지 관측지가 있는 경우 이를 비교하여 차이가 있는지 검정할 때 사용한다. 주로 **실험 전후 효과**를 비교할 때 사용된다. R에서는 기존의 `t.test()` 함수에서 `paired=TRUE` 인자를 추가해주면, 두 집단을(같은 집단이긴 함) 비교할 수 있다.

ex) 0교시 수업을 했더니 10반 애들의 성적이 향상되었다. 라는 것을 검증해보자. '10반 애들의 성적이 이전보다 향상되었다' 라는 것으로 판단할 수 있다. 0교시 이전과 이후는 랜덤으로 추출해주었다. (이후의 성적은 기존에 성적에서 평균이 4이고 표준편차 1인 정규분포를 따르는 집단을 더해주었다. 즉, 상승이 되었다고 미리 판단할 수 있다.)

```R
> before_score <- runif(15, min =30, max=100)
> after_score <- before_score + rnorm(15, mean=4, sd=1)
# paired=TRUE 넣어주지 않으면 이 표본 t-검정을 하게 된다.
> t.test(before_score, after_score, alternative='greater', paired = TRUE)

	Paired t-test

data:  before_score and after_score
#p-value가 높으므로 귀무가설을 신뢰할 수 있다.
t = -16.242, df = 14, p-value = 1
alternative hypothesis: true difference in means is greater than 0
95 percent confidence interval:
 -4.039382       Inf
sample estimates:
mean of the differences 
              -3.644197 

```

위의 분석으로 0교시가 성적향상에 도움이 된다고 판단할 수 있다. 주의할 점은, 이 표본 t-검정은 독립된 두 집단에 대하여 이루어지는 것이고, 대응 표본 t-검정은 한 대상에 대하여 다른 두개의 평가에 대하여 이루어지는 것으로 구분해야한다는 것이다.

## 분산 분석(ANOVA)

**세 개 이상의 모집단이 있을 때, 여러 집단 사이의 평균을 비교**하는 검정 방법이다. 분산분석의 귀무가설은 항상 **<u>H0 : 모든 집단 간 평균은 같다</u>** 이다. 따라서 귀무가설을 기각할 경우, 모든 집단간 *평균은 같지 않다! 정도만 알 수 있으*며 자세한 내용은 알 수 없으므로 사후 검정(Scheffe, Tukey, Duncan, Fisher's LSD, Dunnett, Boferroni 등) 방법을 사용한다.

R에서는 `aov(종속변수~독립변수)`의 방법으로 분산분석을 진행한다! 분석결과의 모델을 다시 분산분석하는 경우(회귀분석, 로지스틱 회귀분석)에는 `anova()`함수를 사용하니 차이를 알고 있도록 하자!

분산분석은 아래의 가정사항을 필요로 한다.

1. 정규성 : 각 집단의 표본들은 정규분포를 따른다.
2. 등분산성 : 각 집단은 동일한 분산을 가져야한다.
3. 독립성 : 각 집단은 서로에게 영향을 주지 않는다.

분산분석에는 F-Value (집단간 분산/집단 내 분산)값이 사용된다.

### one-way Anova(일원 분산분석)

하나의 집단에 속하는 독립변수와 종속변수가 모두 한 개일때 사용한다.

### two-way Anova(이원 분산분석)

일원분산분석 수행 시 독립변수의 수가 두 개 이상일 때 사용한다.

### R에서 분산분석표 읽는 방법

|                        | DF(자유도)                 | Sum Sq(제곱합) | Mean Sq(제곱평균) | F value | Pr(>F) |
| ---------------------- | -------------------------- | -------------- | ----------------- | ------- | ------ |
| 독립변수(집단간)       | a= **집단수 - 1**          | SSR            | MSR = SSR/a       | F값     | P값    |
| Residuals(집단내 잔차) | b= **전체데이터 - 집단수** | SSE            | MSE = SSE/b       |         |        |

## 교차 분석

범주형 자료(질적 척도: 명목, 서열) 간의 관계를 알아보고자 할 때 사용되는 방법이며 카이제곱($x^2$)검정 통계량을 이용한다.

### 교차분석표

두 범주형 변수를 교차하여 데이터의 빈도를 표 형태로 나타낸 것이다.

### 적합도 검정

실험 결과 얻어진 관측값이 **예상값과 일치하는지** 여부를 검정하는 방법이다. 실험 데이터='관측도수', 예측값='기대도수'라고 부른다.

$H_0$ : 실제 분포와 예측 분포간의 차이가 없다. = 두 분포가 일치한다.

### 독립성 검정

모집단이 두 개의 변수에 의해 범주화되었을 때 두 변수 사이의 관계가 독립적인지 아닌지 검정하는 것을 의미한다. 

카이제곱 검정에 의한 독립성 검정 결과는 *관계가 있는지 여부만* 판단하며, 관계의 강도를 표현하지 못한다. 또한, *유의한 관계(종속적인 관계)라고 해서 상관관계가 강하다고 볼 수 없다*!

### 동질성 검정

관측값들이 정해진 범주 내에서 서로 비슷하게 나타나고 있는지를 검정하는 것이다.

## 상관 분석

두 변수간의 선형적 관계가 존재하는지 알아보는 방법, **상관계수**의 값을 이용하여 판단할 수 있다. *상관관계가 있다고 하여 인과관계가 있는 것은 아니다*! 인과관계는 회귀분석에서 다룬다.

상관분석의 $H_0$ : **두 변수는 아무 상관관계가 없다** 이다. 따라서 `p-value`가 낮아야 유의한 상관관계가 있다고 할 수 있다. R에서는 `cor( data_1, data_2, method=' ')`의 방법으로 상관분석을 할 수 있다. 이후, p-value를 보고 귀무가설을 채택하거나, 기각하여 상관관계를 파악할 수 있다.

### 산점도 행렬

R에서는 `pairs()`함수를 이용하여 산점도 행렬을 그릴 수 있으며, 이를 통하여 여러 변수간 상관관계가 높은 것들을 유추하여 확인할 수 있다.

### 상관분석의 종류

1. 피어슨 상관분석(선형적 상관관계, 모수적) : `method = 'pearson'`

   모수적 방법의 분석으로 두 변수가 모두 정규분포를 따른다는 가정이 필요하다.

2. 스피어만 상관분석(비선형적 상관관계, 비모수적) : `method = 'spearman'`

   비모수적 방법의 분석으로 두 변수들이 서열척도일 때 사용하는 상관계수이다. 

### 상관분석 예시

공부시간에 따른 시험점수를 분석해보도록 하자.

```R
> time <- c(8,6,7,3,2,4,2,7,2,3)
> score <- c(33,22,28,6,23,10,9,30,11,13)
> cor.test(time, score)	#default : pearson / method='spearman/pearson'

	Pearson's product-moment correlation

data:  time and score
t = 3.9984, df = 8, p-value = 0.003959
alternative hypothesis: true correlation is not equal to 0
95 percent confidence interval:
 0.3842979 0.9550830
sample estimates:
      cor 
0.8163877
```

p-value가 0.05보다 낮으므로 영가설을 기각할 수 있다. 따라서 두 변수 사이에는 상관관계가 있다고 볼 수 있다. **자유도는 n-2**(집단 2개이니까 그런가?)임을 유추할 수 있다.



나는 직접 실행해보고 결과를 봐야 이해가 되고 외울 수 있는 사람이라 시간들여 공부했지만, 단순하게 검정을 '왜' 하는지, 해당 방법으로는 '무엇을' 알 수 있는지, 어떻게 해석 가능한지 정도만 암기하는 것이 가장 중요할 것 같다.
